# Multi-MCP Model Configuration

version: "1.0"

# Default model
default_model: gpt-5-mini

models:
  # ============================================
  # OpenAI Models
  # ============================================

  gpt-5-nano:
    litellm_model: openai/gpt-5-nano
    aliases:
      - nano
    constraints:
      temperature: 1.0  # gpt-5 family only supports 1.0
    notes: "Fast, cost-effective"

  gpt-5-mini:
    litellm_model: openai/gpt-5-mini
    aliases:
      - mini
    constraints:
      temperature: 1.0  # gpt-5 family only supports 1.0
    notes: "Fast, cost-effective"

  gpt-5.1:
    litellm_model: openai/gpt-5.1
    aliases:
      - gpt-5
      - gpt
    constraints:
      temperature: 1.0
    notes: "Strong general-purpose model, temperature=1.0 only"

  gpt-5.1-codex-mini:
    litellm_model: openai/gpt-5.1-codex-mini
    aliases:
      - codex-mini
    constraints:
      temperature: 1.0
    notes: "Strong general-purpose model, temperature=1.0 only"

  gpt-5.1-codex:
    litellm_model: openai/gpt-5.1-codex
    aliases:
      - codex
    constraints:
      temperature: 1.0
    notes: "Strong general-purpose model, temperature=1.0 only"

  # ============================================
  # Anthropic Models
  # ============================================

  claude-haiku-4.5:
    litellm_model: anthropic/claude-haiku-4-5-20251001
    aliases:
      - haiku
    notes: "Fast claude model"

  claude-sonnet-4.5:
    litellm_model: anthropic/claude-sonnet-4-5-20250929
    aliases:
      - sonnet
    notes: "Great for reasoning and analysis"

  claude-opus-4.5:
    litellm_model: anthropic/claude-opus-4-5-20251101
    aliases:
      - opus
    notes: "Best in class from anthropic"

  # ============================================
  # Google Models
  # ============================================

  gemini-2.5-pro:
    litellm_model: gemini/gemini-2.5-pro
    aliases:
      - gemini-2.5
      - gemini-2
    notes: "High-quality Google model"

  gemini-2.5-flash:
    litellm_model: gemini/gemini-2.5-flash
    aliases:
      - gemini-flash
      - flash
    notes: "Fast and cheap"

  gemini-3-pro-preview:
    litellm_model: gemini/gemini-3-pro-preview
    aliases:
      - gemini-3-pro
      - gemini-3
      - gemini
    notes: "Latest Google model"

  # ============================================
  # CLI Models
  # ============================================

  gemini-cli:
    provider: cli
    cli_command: gemini
    cli_args:
      - "-o"
      - "json"
      - "--yolo"
    cli_env:
      GEMINI_API_KEY: "${GEMINI_API_KEY}"
    cli_parser: json
    aliases:
      - gemcli
    notes: "Gemini CLI with full tool access"

  codex-cli:
    provider: cli
    cli_command: codex
    cli_args:
      - "exec"
      - "--json"
      - "--dangerously-bypass-approvals-and-sandbox"
    cli_env: {}
    cli_parser: jsonl
    aliases:
      - cxcli
    notes: "Codex CLI with full tool access"

  claude-cli:
    provider: cli
    cli_command: claude
    cli_args:
      - "--output-format"
      - "json"
    cli_env:
      ANTHROPIC_API_KEY: "${ANTHROPIC_API_KEY}"
    cli_parser: json
    aliases:
      - clcli
    notes: "Claude CLI with full tool access"

  # ============================================
  # OpenRouter Models
  # ============================================

  # deepseek-chat:
  #   litellm_model: openrouter/deepseek/deepseek-chat-v3-0324
  #   aliases:
  #     - deepseek
  #   notes: "DeepSeek Chat via OpenRouter"

  # deepseek-r1:
  #   litellm_model: openrouter/deepseek/deepseek-r1
  #   aliases:
  #     - r1
  #   notes: "DeepSeek R1 reasoning model via OpenRouter"

  # qwen-coder:
  #   litellm_model: openrouter/qwen/qwen-2.5-coder-32b-instruct
  #   aliases:
  #     - qwen
  #   notes: "Qwen 2.5 Coder via OpenRouter"
